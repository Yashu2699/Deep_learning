{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgs79+9kNwVx25TEDvTSAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashu2699/Deep_learning/blob/main/GAN/fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xHFIn7z9Cw1w"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(training_data, _), (_, _) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SARWFLxHEhSe",
        "outputId": "453f9d42-fd3c-4f04-e7e9-8fb31da8ee55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = training_data / 127.5 - 1\n",
        "x_train = np.expand_dims(x_train, axis=3)"
      ],
      "metadata": {
        "id": "FTplkj5lExgb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(128*7*7, activation='relu', input_dim=latent_dim))\n",
        "  model.add(Reshape((7,7,128)))\n",
        "  model.add(UpSampling2D())\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(UpSampling2D())\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "  model.add(Conv2D(channels, kernel_size=3, activation='tanh', padding='same'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  noise = Input(shape=(latent_dim, ))\n",
        "  img = model(noise)\n",
        "\n",
        "  return Model(noise, img)"
      ],
      "metadata": {
        "id": "UafX73dsE6HX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape= img_shape, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape= img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)"
      ],
      "metadata": {
        "id": "n31x8O7RGQ0m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img_shape = (28, 28, 1)\n",
        "channels = 1\n",
        "latent_dim = 100\n",
        "\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "#build and compile the discriminator\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "#build the generator\n",
        "generator = build_generator()\n",
        "\n",
        "z = Input(shape=(latent_dim, ))\n",
        "img = generator(z)\n",
        "\n",
        "discriminator.trainable = False\n",
        "valid = discriminator(img)\n",
        "\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBmF94d6GltC",
        "outputId": "2a95e516-3563-4a5d-88a9-5d642ead587a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 32)        320       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "                                                                 \n",
            " zero_padding2d (ZeroPadding  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 8, 8, 64)         256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 4, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 393,729\n",
            "Trainable params: 392,833\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 6272)              633472    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 14, 14, 128)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 28, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 1)         577       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 856,193\n",
            "Trainable params: 855,809\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size=128, save_interval=50):\n",
        "  valid = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    #train discriminator\n",
        "    idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "    imgs = x_train[idx]\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "    d_loss = 0.5* np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "    #train generator\n",
        "    g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "    print(\"%d [D loss: %f, acc: %.2f] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "    if(epoch % save_interval == 0):\n",
        "      plot_generated_images(epoch, generator)"
      ],
      "metadata": {
        "id": "5WWyoTvDHieR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)"
      ],
      "metadata": {
        "id": "kvImq7wrJFIh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(epochs=1000, batch_size=32, save_interval=1)"
      ],
      "metadata": {
        "id": "AKhGA-aVJgoA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}