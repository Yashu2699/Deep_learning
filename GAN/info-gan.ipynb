{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from numpy import zeros, ones, expand_dims, hstack\nfrom numpy.random import randn, randint\nfrom keras.datasets.mnist import load_data\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose,\\\nLeakyReLU, BatchNormalization, Activation\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:08:35.182052Z","iopub.execute_input":"2022-04-21T05:08:35.182358Z","iopub.status.idle":"2022-04-21T05:08:36.898678Z","shell.execute_reply.started":"2022-04-21T05:08:35.182295Z","shell.execute_reply":"2022-04-21T05:08:36.897961Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def define_discriminator(n_cat, in_shape=(28,28,1)):\n    init = RandomNormal(stddev=0.02)\n    in_image = Input(shape=in_shape)\n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n    d = LeakyReLU(alpha=0.1)(d)\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = LeakyReLU(alpha=0.1)(d)\n    d = BatchNormalization()(d)\n    d = Conv2D(256, (4,4), padding='same', kernel_initializer=init)(d)\n    d = LeakyReLU(alpha=0.1)(d)\n    d = BatchNormalization()(d)\n    d = Flatten()(d)\n    out_classifier = Dense(1, activation='sigmoid')(d)\n    d_model = Model(in_image, out_classifier)\n    d_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n    q = Dense(128)(d)\n    q = LeakyReLU(alpha=0.1)(q)\n    q = BatchNormalization()(q)\n    out_codes = Dense(n_cat, activation='softmax')(q)\n    q_model = Model(in_image, out_codes)\n    return d_model, q_model","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:08:36.902619Z","iopub.execute_input":"2022-04-21T05:08:36.902999Z","iopub.status.idle":"2022-04-21T05:08:36.914782Z","shell.execute_reply.started":"2022-04-21T05:08:36.902964Z","shell.execute_reply":"2022-04-21T05:08:36.914008Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def define_generator(gen_input_size):\n    init = RandomNormal(stddev=0.02)\n    in_lat = Input(shape=(gen_input_size, ))\n    gen = Dense(512*7*7, kernel_initializer=init)(in_lat)\n    gen = Activation('relu')(gen)\n    gen = BatchNormalization()(gen)\n    gen = Reshape((7,7,512))(gen)\n    gen = Conv2D(128, (4,4), padding='same', kernel_initializer=init)(gen)\n    gen = Activation('relu')(gen)\n    gen = BatchNormalization()(gen)\n    gen = Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n    gen = Activation('relu')(gen)\n    gen = BatchNormalization()(gen)\n    gen = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n    out_layer = Activation('tanh')(gen)\n    model = Model(in_lat, out_layer)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:08:36.916010Z","iopub.execute_input":"2022-04-21T05:08:36.916327Z","iopub.status.idle":"2022-04-21T05:08:36.926808Z","shell.execute_reply.started":"2022-04-21T05:08:36.916290Z","shell.execute_reply":"2022-04-21T05:08:36.926104Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def define_gan(g_model, d_model, q_model):\n    d_model.trainable = False\n    d_output = d_model(g_model.output)\n    q_output = q_model(g_model.output)\n    model = Model(g_model.input, [d_output, q_output])\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:08:36.930094Z","iopub.execute_input":"2022-04-21T05:08:36.930797Z","iopub.status.idle":"2022-04-21T05:08:36.938429Z","shell.execute_reply.started":"2022-04-21T05:08:36.930764Z","shell.execute_reply":"2022-04-21T05:08:36.937611Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_real_samples():\n    (trainX, _), (_, _) = load_data()\n    X = expand_dims(trainX, axis=-1)\n    X = X.astype('float32')\n    X = (X - 127.5) / 127.5\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:08:36.939448Z","iopub.execute_input":"2022-04-21T05:08:36.940562Z","iopub.status.idle":"2022-04-21T05:08:36.947578Z","shell.execute_reply.started":"2022-04-21T05:08:36.940525Z","shell.execute_reply":"2022-04-21T05:08:36.946827Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def generate_real_samples(dataset, n_samples):\n    idx = randint(0, dataset.shape[0], n_samples)\n    X = dataset[idx]\n    y = ones((n_samples, 1))\n    return X, y","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:08:36.949113Z","iopub.execute_input":"2022-04-21T05:08:36.949604Z","iopub.status.idle":"2022-04-21T05:08:36.956918Z","shell.execute_reply.started":"2022-04-21T05:08:36.949567Z","shell.execute_reply":"2022-04-21T05:08:36.956206Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def generate_latent_points(latent_dim, n_cat, n_samples):\n    z_latent = randn(latent_dim * n_samples)\n    z_latent = z_latent.reshape((n_samples, latent_dim))\n    cat_codes = randint(0, n_cat, n_samples)\n    cat_codes = to_categorical(cat_codes, num_classes=n_cat)\n    z_input = hstack((z_latent, cat_codes))\n    #print(z_latent.shape, cat_codes.shape)\n    return z_input, cat_codes","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:25:18.426434Z","iopub.execute_input":"2022-04-21T05:25:18.426865Z","iopub.status.idle":"2022-04-21T05:25:18.433264Z","shell.execute_reply.started":"2022-04-21T05:25:18.426831Z","shell.execute_reply":"2022-04-21T05:25:18.432555Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def generate_fake_samples(generator, latent_dim, n_cat, n_samples):\n    z_input, _ = generate_latent_points(latent_dim, n_cat, n_samples)\n    images = generator.predict(z_input)\n    y = zeros((n_samples, 1))\n    return images, y","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:21:51.526566Z","iopub.execute_input":"2022-04-21T05:21:51.527346Z","iopub.status.idle":"2022-04-21T05:21:51.532538Z","shell.execute_reply.started":"2022-04-21T05:21:51.527306Z","shell.execute_reply":"2022-04-21T05:21:51.531662Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def summarize_performance(step, g_model, gan_model, latent_dim, n_cat, n_samples=100):\n    X, _ = generate_fake_samples(g_model, latent_dim, n_cat, n_samples)\n    X = (X + 1) / 2.0\n    for i in range(100):\n        plt.subplot(10, 10, 1+i)\n        plt.axis('off')\n        plt.imshow(X[i, :, :, 0], cmap='gray_r')\n    filename1 = 'generated_plot_%04d.png' %(step+1)\n    plt.save(filename1)\n    plt.close()\n    filename2 = 'model_%04d.h5' %(step+1)\n    g_model.save(filename2)\n    filename3 = 'gan_model_%04d.h5' %(step+1)\n    gan_model.save(filename3)\n    print('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:21:52.005765Z","iopub.execute_input":"2022-04-21T05:21:52.006121Z","iopub.status.idle":"2022-04-21T05:21:52.020445Z","shell.execute_reply.started":"2022-04-21T05:21:52.006081Z","shell.execute_reply":"2022-04-21T05:21:52.019440Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train(g_model, d_model, q_model, dataset, latent_dim, n_cat, n_epochs=100, n_batch=64):\n    batch_per_epoch = int(dataset.shape[0] / n_batch)\n    n_steps = batch_per_epoch * n_epochs\n    half_batch = int(n_batch / 2)\n    for i in range(n_steps):\n        X_real, y_real = generate_real_samples(dataset, half_batch)\n        d_loss1 = d_model.train_on_batch(X_real, y_real)\n        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_cat, half_batch)\n        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n        z_input, cat_codes = generate_latent_points(latent_dim, n_cat, n_batch)\n        y_gan = ones((n_batch, 1))\n        _, g_1, g_2 = gan_model.train_on_batch(z_input, [y_gan, cat_codes])\n        print('>%d, d[%.3f, %.3f], g[%.3f], q[%.3f]' % (i+1, d_loss1, d_loss2, g_1, g_2))\n        if (i + 1) % (batch_per_epoch * 10) == 0:\n            summarize_performance(i, g_model, gan_model, dataset, latent_dim, n_cat)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:21:52.488049Z","iopub.execute_input":"2022-04-21T05:21:52.488468Z","iopub.status.idle":"2022-04-21T05:21:52.497134Z","shell.execute_reply.started":"2022-04-21T05:21:52.488415Z","shell.execute_reply":"2022-04-21T05:21:52.496170Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"n_cat = 10\nlatent_dim = 62\nd_model, q_model = define_discriminator(n_cat)\ngen_input_size = latent_dim + n_cat\ng_model = define_generator(gen_input_size)\ngan_model = define_gan(g_model, d_model, q_model)\ndataset = load_real_samples()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:21:53.209221Z","iopub.execute_input":"2022-04-21T05:21:53.209637Z","iopub.status.idle":"2022-04-21T05:21:53.832735Z","shell.execute_reply.started":"2022-04-21T05:21:53.209603Z","shell.execute_reply":"2022-04-21T05:21:53.831924Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train(g_model, d_model, gan_model, dataset, latent_dim, n_cat)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:25:23.197435Z","iopub.execute_input":"2022-04-21T05:25:23.197699Z","iopub.status.idle":"2022-04-21T05:36:30.045832Z","shell.execute_reply.started":"2022-04-21T05:25:23.197672Z","shell.execute_reply":"2022-04-21T05:36:30.044592Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#Loading and predicting \nfrom math import sqrt\nfrom keras.models import load_model\nimport numpy as np","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_plot(examples, n_examples):\n    for i in range(n_examples):\n        plt.subplot(sqrt(n_examples), sqrt(n_examples), 1+i)\n        plt.axis('off')\n        plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('model_93700.h5')\nn_cat = 10\nlatent_dim = 62\nn_samples = 100\nz_input, _ = generate_latent_points(latent_dim, n_cat, n_samples)\nX = model.predict(z_input)\nX = X + 1 / 2.0\ncreate_plot(X, n_samples)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using the control variables\ndef generate_latent_points(latent_dim, n_cat, n_samples, digit):\n    z_latent = randn(latent_dim * n_samples)\n    z_latent = z_latent.reshape(n_samples, latent_dim)\n    cat_codes = np.asarray([digit for _ in range(n_samples)])\n    cat_codes = to_categorical(cat_codes, num_classes=n_cat)\n    z_input = hstack((z_latent, cat_codes))\n    return [z_input, cat_codes]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('model_93700.h5')\nn_cat = 10\nlatent_dim = 62\nn_samples = 100\ndigit = 2\nz_input, _ = generate_latent_points(latent_dim, n_cat, n_samples, digit)\nX = model.predict(z_input)\nX = X + 1 / 2.0\ncreate_plot(X, n_samples)","metadata":{},"execution_count":null,"outputs":[]}]}