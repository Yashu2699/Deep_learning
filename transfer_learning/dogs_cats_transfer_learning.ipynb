{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogs_cats_transfer_learning",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/rsV6nANy2/WFWppFuTRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashu2699/Deep_learning/blob/main/transfer_learning/dogs_cats_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JvaTqmKhyxR"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.applications import vgg16\n",
        "from keras.applications import mobilenet\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.metrics import categorical_crossentropy\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJeDPelAix1D"
      },
      "source": [
        "train_path = \"D:/vision/deep_learning_for_vision_systems-master/deep_learning_for_vision_systems-master/chapter_06/dogs_vs_cats_project/data/train\"\n",
        "valid_path = \"D:/vision/deep_learning_for_vision_systems-master/deep_learning_for_vision_systems-master/chapter_06/dogs_vs_cats_project/data/valid\"\n",
        "test_path = \"D:/vision/deep_learning_for_vision_systems-master/deep_learning_for_vision_systems-master/chapter_06/dogs_vs_cats_project/data/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK5glL1GjKDi"
      },
      "source": [
        "train_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(train_path, target_size=(224,224), batch_size=30)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(valid_path, target_size=(224,224), batch_size=30)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=vgg16.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yvYDM5OjgAV"
      },
      "source": [
        "base_model = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgcKCwyNOQlm"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si9resUcOQoH"
      },
      "source": [
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "last_layer = base_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = Flatten()(last_output)\n",
        "x = Dense(64, activation='relu', name='FC2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(2, activation='softmax', name='softmax')(x)\n",
        "\n",
        "new_model = Model(inputs=base_model.input, outputs=x)\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoRV5vvlOQra"
      },
      "source": [
        "new_model.compile(Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnL9wHOrOQt8"
      },
      "source": [
        "new_model.fit_generator(train_batches, steps_per_epoch=4, validation_data=valid_batches, validation_steps=2, epochs=20, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJTHpdBLOZlG"
      },
      "source": [
        "def load_dataset(path):\n",
        "    data = load_files(path)\n",
        "    paths = np.array(data['filenames'])\n",
        "    targets = np_utils.to_categorical(np.array(data['target']))\n",
        "    return paths, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxRWtbRjOZoC"
      },
      "source": [
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "\n",
        "test_files, test_targets = load_dataset('data/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDV8BcfEOZrA"
      },
      "source": [
        "from keras.preprocessing import image  \n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tqdm import tqdm\n",
        "\n",
        "def path_to_tensor(img_path):\n",
        "    # loads RGB image as PIL.Image.Image type\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
        "    x = image.img_to_array(img)\n",
        "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
        "    return np.expand_dims(x, axis=0)\n",
        "\n",
        "def paths_to_tensor(img_paths):\n",
        "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
        "    return np.vstack(list_of_tensors)\n",
        "\n",
        "test_tensors = preprocess_input(paths_to_tensor(test_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_fp8YfOfUr"
      },
      "source": [
        "acc = new_model.evaluate(test_tensors, test_targets)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}